{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow_datasets as tfds\r\n",
    "import tensorflow.keras as keras\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from scipy.io import loadmat\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd\r\n",
    "import h5py\r\n",
    "import numpy as np\r\n",
    "import glob\r\n",
    "import os\r\n",
    "from PIL import Image\r\n",
    "from sklearn import preprocessing\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import cv2\r\n",
    "\r\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_dir = \"animedata/full_dataset/animefaces\"\r\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir+'*/*'))\r\n",
    "IMG_HEIGHT = 72\r\n",
    "IMG_WIDTH = 72\r\n",
    "BATCH_SIZE = 32\r\n",
    "#CLASS_NAMES = ['animefaces']\r\n",
    "AUTOTUNE=tf.data.experimental.AUTOTUNE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for f in list_ds.take(5):\r\n",
    "    print(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def decode_img(img):\r\n",
    "  # convert the compressed string to a 3D uint8 tensor\r\n",
    "  img = tf.image.decode_jpeg(img, channels=3)\r\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\r\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\r\n",
    "  # resize the image to the desired size.\r\n",
    "  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\r\n",
    "@tf.autograph.experimental.do_not_convert\r\n",
    "def process_path(file_path):\r\n",
    "    # load the raw data from the file as a string\r\n",
    "    img = tf.io.read_file(file_path)\r\n",
    "    img = decode_img(img)\r\n",
    "    return img\r\n",
    "@tf.autograph.experimental.do_not_convert\r\n",
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\r\n",
    "    # use caching if the data is too large for the memory\r\n",
    "    if cache:\r\n",
    "        if isinstance(cache, str):\r\n",
    "            ds = ds.cache(cache)\r\n",
    "        else:\r\n",
    "            ds = ds.cache()\r\n",
    "    # shuffle\r\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\r\n",
    "\r\n",
    "    # Repeat forever\r\n",
    "    ds = ds.repeat()\r\n",
    "    ds = ds.batch(BATCH_SIZE)\r\n",
    "\r\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\r\n",
    "  # is training.\r\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\r\n",
    "\r\n",
    "    return ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check if the image shape is correct\r\n",
    "for image in full_ds.take(1):\r\n",
    "    print(\"Input Image shape: \", image.numpy().shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "steps_per_epoch = None\r\n",
    "def show_batch(image_batch):\r\n",
    "    plt.figure(figsize=(25,25))\r\n",
    "    for n in range(BATCH_SIZE):\r\n",
    "        ax = plt.subplot(8,BATCH_SIZE/8,n+1)\r\n",
    "        plt.imshow(image_batch[n])\r\n",
    "        plt.axis('off')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_ds = prepare_for_training(full_ds)\r\n",
    "#image_batch = next(iter(full_ds))\r\n",
    "#show_batch(image_batch.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#full_ds = full_ds.shuffle()\r\n",
    "# split train and test if required\r\n",
    "train_ds = full_ds.take(50000)\r\n",
    "test_ds = full_ds.skip(50000)\r\n",
    "train_np = tfds.as_numpy(train_ds)\r\n",
    "it = iter(train_ds)\r\n",
    "train_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def def_discriminator(shape=(72,72,3)):\r\n",
    "    inputs = keras.Input(shape)\r\n",
    "    x = keras.layers.Conv2D(filters = 100, kernel_size = (4,4),strides = 2, padding = 'same', activation = \"relu\")(inputs)\r\n",
    "    #x = keras.layers.MaxPooling2D((2,2), padding = 'same')(x)\r\n",
    "    x = keras.layers.BatchNormalization()(x)\r\n",
    "    x = keras.layers.Conv2D(filters = 100, kernel_size = (4,4),strides = 2, padding = 'same', activation = \"relu\")(x)\r\n",
    "    #x = keras.layers.MaxPooling2D((2,2), padding = 'same')(x)\r\n",
    "    x = keras.layers.BatchNormalization()(x)\r\n",
    "    x = keras.layers.Conv2D(filters = 100, kernel_size = (2,2),strides = 2, padding = 'same', activation = \"relu\")(x)\r\n",
    "    x = keras.layers.MaxPooling2D((2,2), padding = 'same')(x)\r\n",
    "    x = keras.layers.Flatten()(x)\r\n",
    "    x = keras.layers.Dense(50)(x)\r\n",
    "    x = keras.layers.Dropout(0.5)(x)\r\n",
    "    x = keras.layers.BatchNormalization()(x)\r\n",
    "    output = keras.layers.Dense(2, activation = 'softmax')(x)\r\n",
    "    model = keras.Model(inputs,output)\r\n",
    "    opt = keras.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5)\r\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\r\n",
    "    return model\r\n",
    "disc_model = def_discriminator()\r\n",
    "disc_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def def_generator(latent_dim):\r\n",
    "    inputs = keras.Input((latent_dim,))\r\n",
    "    x = keras.layers.Dense(9*9*100)(inputs)\r\n",
    "    x = keras.layers.LeakyReLU(alpha=0.2)(x)\r\n",
    "    x = keras.layers.Reshape((9,9,100))(x)\r\n",
    "    x = keras.layers.Conv2DTranspose(140,(2,2),strides=(2,2),padding='same')(x)\r\n",
    "    x = keras.layers.LeakyReLU(alpha=0.2)(x)\r\n",
    "    #x = keras.layers.Dropout(0.2)(x)\r\n",
    "    x = keras.layers.Conv2DTranspose(140,(4,4),strides=(2,2),padding='same')(x)\r\n",
    "    x = keras.layers.LeakyReLU(alpha=0.2)(x)\r\n",
    "    x = keras.layers.Conv2DTranspose(100,(5,5),strides=(2,2),padding='same')(x)\r\n",
    "    x = keras.layers.LeakyReLU(alpha=0.2)(x)\r\n",
    "    #x = keras.layers.Dropout(0.4)(x)\r\n",
    "    output = keras.layers.Conv2D(3,(4,4),activation='tanh',padding='same')(x)\r\n",
    "    model = keras.Model(inputs,output)\r\n",
    "    return model\r\n",
    "latent_dim = 128\r\n",
    "gen_model = def_generator(latent_dim)\r\n",
    "gen_model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.autograph.experimental.do_not_convert\r\n",
    "def def_gan(gen_model,disc_model):\r\n",
    "    disc_model.trainable = False\r\n",
    "    model = keras.Sequential()\r\n",
    "    model.add(gen_model)\r\n",
    "    model.add(disc_model)\r\n",
    "    opt = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\r\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt)\r\n",
    "    return model\r\n",
    "gan_model = def_gan(gen_model, disc_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def select_real_samples(dataset, n_samples):\r\n",
    "    # choose random instances\r\n",
    "    X = np.array(dataset[:n_samples])\r\n",
    "    # generate 'real' class labels (1)\r\n",
    "    y = np.full((n_samples, 2),[0,1])\r\n",
    "    return X, y\r\n",
    "def generate_latent_points(latent_dim, n_samples):\r\n",
    "    # generate points in the latent space\r\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\r\n",
    "    # reshape into a batch of inputs for the network\r\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\r\n",
    "    return x_input\r\n",
    "def generate_fake_samples(gen_model, latent_dim, n_samples):\r\n",
    "    # generate points in latent space\r\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\r\n",
    "    # predict outputs\r\n",
    "    X = gen_model.predict(x_input)\r\n",
    "    # create 'fake' class labels (0)\r\n",
    "    y = np.full((n_samples, 2),[0,0])\r\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "keras.models.Model.tr = tf.autograph.experimental.do_not_convert(func=keras.models.Model.train_on_batch)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_batches = 50000/BATCH_SIZE\r\n",
    "epochs = 10\r\n",
    "bat_per_epo = int(n_batches/epochs)\r\n",
    "# half batch - to train disc one half with fake and other half with real\r\n",
    "half_batch = int(BATCH_SIZE/2)\r\n",
    "# iterate over epochs\r\n",
    "for i in range(epochs):\r\n",
    "    # enumerate batches over the training set\r\n",
    "    for j in range(bat_per_epo):\r\n",
    "        # get randomly selected 'real' samples\r\n",
    "        X_real, y_real = select_real_samples(next(iter(train_ds)), half_batch)\r\n",
    "        # update discriminator model weights using real samples\r\n",
    "        #d_loss1, acc1 = disc_model.tr(X_real, y_real)\r\n",
    "        # generate 'fake' examples\r\n",
    "        X_fake, y_fake = generate_fake_samples(gen_model, latent_dim, half_batch)\r\n",
    "        # update discriminator model weights using fake samples\r\n",
    "        #d_loss2, acc2 = disc_model.tr(X_fake, y_fake)\r\n",
    "        X = np.r_[X_real,X_fake]\r\n",
    "        y = np.r_[y_real,y_fake]\r\n",
    "        X = tf.convert_to_tensor(X)\r\n",
    "        y = tf.convert_to_tensor(y)\r\n",
    "        #a,b = shuffle(X,y, random_state=0)\r\n",
    "        d_loss1, acc1 = disc_model.train_on_batch(X, y)\r\n",
    "        \r\n",
    "        # we update generator 5 times per one training of disc\r\n",
    "\r\n",
    "        for k in range(3):\r\n",
    "            # prepare points in latent space as input for the generator\r\n",
    "            X_gan = generate_latent_points(latent_dim, BATCH_SIZE)\r\n",
    "            # create inverted labels for the fake samples\r\n",
    "            y_gan = np.full((BATCH_SIZE, 2),[0,1])\r\n",
    "            # update the generator via the discriminator's error until disc loss increases\r\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\r\n",
    "        \r\n",
    "    # summarize loss after this epoch\r\n",
    "    #print('>%d, %d/%d, d1=%.3f, acc1=%.3f'%(i+1, j+1, bat_per_epo, d_loss1,acc1))\r\n",
    "    print('>%d, %d/%d, d1=%.3f, acc1=%.3f ,g=%.3f'%(i+1, j+1, bat_per_epo, d_loss1,acc1, g_loss))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_images(images, n):\r\n",
    "    plt.figure(figsize=(20,20))\r\n",
    "    for i in range(n * n):\r\n",
    "        plt.subplot(n, n, 1 + i)\r\n",
    "        plt.axis('off')\r\n",
    "        plt.imshow(images[i, :, :])\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "latent_points = generate_latent_points(latent_dim, 128)\r\n",
    "predicted_images = gen_model.predict(latent_points)\r\n",
    "print(\"Generated Images\")\r\n",
    "# plot the result\r\n",
    "plot_images(predicted_images.clip(0,1), 4)\r\n",
    "print(\"\\n\\n\\n\\nReal Images\")\r\n",
    "plot_images(next(iter(train_ds)), 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}